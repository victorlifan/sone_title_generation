{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ctext</th>\n",
       "      <th>Number_of_words</th>\n",
       "      <th>Number_of_words_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>careless whisper</td>\n",
       "      <td>i feel so unsure as i take your hand and lead ...</td>\n",
       "      <td>299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>could you be loved</td>\n",
       "      <td>don't let them fool, ya or even try to school,...</td>\n",
       "      <td>161</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cruisin'</td>\n",
       "      <td>baby, let's cruise, away from here don't be co...</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>easy</td>\n",
       "      <td>know it sounds funny but, i just can't stand t...</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your babies</td>\n",
       "      <td>you've got that look again the one i hoped i h...</td>\n",
       "      <td>215</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191809</th>\n",
       "      <td>the waiting</td>\n",
       "      <td>chorus here we stand waiting on the plain dark...</td>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191810</th>\n",
       "      <td>too early for the sky</td>\n",
       "      <td>i nearly disappeared into the mouth of a croco...</td>\n",
       "      <td>137</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191811</th>\n",
       "      <td>warsaw 1943</td>\n",
       "      <td>amambuka, amambuka azothengisa izwe lakithi, i...</td>\n",
       "      <td>221</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191812</th>\n",
       "      <td>when the system has fallen</td>\n",
       "      <td>sweat in the heat for days on end waiting for ...</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191813</th>\n",
       "      <td>woman be my country</td>\n",
       "      <td>here we stand on the edge of the day faces mel...</td>\n",
       "      <td>302</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191814 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "0                 careless whisper   \n",
       "1               could you be loved   \n",
       "2                         cruisin'   \n",
       "3                             easy   \n",
       "4                  for your babies   \n",
       "...                            ...   \n",
       "191809                 the waiting   \n",
       "191810       too early for the sky   \n",
       "191811                 warsaw 1943   \n",
       "191812  when the system has fallen   \n",
       "191813         woman be my country   \n",
       "\n",
       "                                                    ctext  Number_of_words  \\\n",
       "0       i feel so unsure as i take your hand and lead ...              299   \n",
       "1       don't let them fool, ya or even try to school,...              161   \n",
       "2       baby, let's cruise, away from here don't be co...              159   \n",
       "3       know it sounds funny but, i just can't stand t...              175   \n",
       "4       you've got that look again the one i hoped i h...              215   \n",
       "...                                                   ...              ...   \n",
       "191809  chorus here we stand waiting on the plain dark...              198   \n",
       "191810  i nearly disappeared into the mouth of a croco...              137   \n",
       "191811  amambuka, amambuka azothengisa izwe lakithi, i...              221   \n",
       "191812  sweat in the heat for days on end waiting for ...              260   \n",
       "191813  here we stand on the edge of the day faces mel...              302   \n",
       "\n",
       "        Number_of_words_title  \n",
       "0                           2  \n",
       "1                          11  \n",
       "2                           3  \n",
       "3                           1  \n",
       "4                           6  \n",
       "...                       ...  \n",
       "191809                      2  \n",
       "191810                      5  \n",
       "191811                      7  \n",
       "191812                      5  \n",
       "191813                      4  \n",
       "\n",
       "[191814 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/clean.csv')\n",
    "df.rename(columns={\"SName\": \"title\", \"Lyric\": \"ctext\"},inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./data/renamed_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Transformer for Summary Generation (Song title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Introduction\n",
    "\n",
    "In this tutorial we will be fine tuning a transformer model for **Summarization Task**. \n",
    "In this task a song title of a given lyric is generated when passed through a network. There are 2 types of summary generation mechanisms:\n",
    "\n",
    "1. ***Extractive Summary:*** the network calculates the most important sentences from the text and gets them together to provide the most meaningful information from the text.\n",
    "2. ***Abstractive Summary***: The network creates new sentences to encapsulate maximum gist of the text and generates that as output. The sentences in the summary may or may not be contained in the text. \n",
    "\n",
    "In this tutorial we will be generating ***Abstractive Summary***. \n",
    "\n",
    "#### Flow of the notebook\n",
    "\n",
    "* In the tutorial, most of the sections have been created into functions, and they are called from the `main()` in the end of the notebook. \n",
    "* This is done to leverage the [Weights and Biases Service](https://www.wandb.com/) WandB in short.\n",
    "* It is a experiment tracking, parameter optimization and artifact management service. That can be very easily integrated to any of the Deep learning or Machine learning frameworks. \n",
    "\n",
    "The notebook will be divided into separate sections to provide a organized walk through for the process used. This process can be modified for individual use cases. The sections are:\n",
    "\n",
    "1. [Preparing Environment and Importing Libraries](#section01)\n",
    "2. [Preparing the Dataset for data processing: Class](#section02)\n",
    "3. [Fine Tuning the Model: Function](#section03)\n",
    "4. [Validating the Model Performance: Function](#section04)\n",
    "5. [Main Function](#section05)\n",
    "    * [Initializing WandB](#section501)\n",
    "    * [Importing and Pre-Processing the domain data](#section502)\n",
    "    * [Creation of Dataset and Dataloader](#section503)\n",
    "    * [Neural Network and Optimizer](#section504)\n",
    "    * [Training Model and Logging to WandB](#section505)\n",
    "    * [Validation and generation of Summary](#section506)\n",
    "6. [Examples of the Summary Generated from the model](#section06)\n",
    "\n",
    "\n",
    "#### Technical Details\n",
    "\n",
    "This script leverages on multiple tools designed by other teams. Details of the tools used below. Please ensure that these elements are present in your setup to successfully implement this script.\n",
    "\n",
    "- **Data**:\n",
    "\t- We are using the Song lyrics from 79 musical genres dataset available at [Kaggle](https://www.kaggle.com/datasets/neisse/scrapped-lyrics-from-6-genres?select=lyrics-data.csv)\n",
    "\t- All the data were obtained by scraping the Brazilian website Vagalume using R by the ower of the data set on kaggle. We are referring only to the second csv file from the data dump: `lyrics-data.csv`\n",
    "\t- After preprocessing, there are`191814` rows of data.  Where each row has the following data-point:\n",
    "\t\t- **title** : Song's name\n",
    "\t\t- **ctext** : Song lyrics\n",
    "\t\t- **Number_of_words**: Number of words in lyrics\n",
    "\t\t- **Number_of_words_title**: Number of words in title\n",
    "\n",
    "\n",
    "- **Language Model Used**: \n",
    "    - This notebook uses one of the most recent and novel transformers model ***T5***. [Research Paper](https://arxiv.org/abs/1910.10683)    \n",
    "    - ***T5*** in many ways is one of its kind transformers architecture that not only gives state of the art results in many NLP tasks, but also has a very radical approach to NLP tasks.\n",
    "    - **Text-2-Text** - According to the graphic taken from the T5 paper. All NLP tasks are converted to a **text-to-text** problem. Tasks such as translation, classification, summarization and question answering, all of them are treated as a text-to-text conversion problem, rather than seen as separate unique problem statements.\n",
    "    - **Unified approach for NLP Deep Learning** - Since the task is reflected purely in the text input and output, you can use the same model, objective, training procedure, and decoding process to ANY task. Above framework can be used for any task - show Q&A, summarization, etc. \n",
    "   - We will be taking inputs from the T5 paper to prepare our dataset prior to fine tuning and training.    \n",
    "   - [Documentation for python](https://huggingface.co/transformers/model_doc/t5.html)\n",
    "\n",
    "![**Each NLP problem as a “text-to-text” problem** - input: text, output: text](https://miro.medium.com/max/4006/1*D0J1gNQf8vrrUpKeyD8wPA.png) \n",
    "\t \n",
    "\n",
    "\n",
    "- Hardware Requirements: \n",
    "\t- Python 3.6 and above\n",
    "\t- Pytorch, Transformers and\n",
    "\t- All the stock Python ML Library\n",
    "\t- GPU enabled setup \n",
    "   \n",
    "\n",
    "- **Script Objective**:\n",
    "\t- The objective of this script is to fine tune ***T5 *** to be able to generate title (summary task), that a close to or better than the actual title while ensuring the important information from the lyrics is not lost.\n",
    "\n",
    "---\n",
    "NOTE: \n",
    "We are using the Weights and Biases Tool-set in  this tutorial. The different components will be explained as we go through the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section01'></a>\n",
    "### Preparing Environment and Importing Libraries\n",
    "\n",
    "At this step we will be installing the necessary libraries followed by importing the libraries and modules needed to run our script. \n",
    "We will be installing:\n",
    "* transformers\n",
    "* wandb\n",
    "\n",
    "Libraries imported are:\n",
    "* Pandas\n",
    "* Pytorch\n",
    "* Pytorch Utils for Dataset and Dataloader\n",
    "* Transformers\n",
    "* T5 Model and Tokenizer\n",
    "* wandb\n",
    "\n",
    "Followed by that we will preapre the device for CUDA execeution. This configuration is needed if you want to leverage on onboard GPU. First we will check the GPU avaiable to us, using the nvidia command followed by defining our device.\n",
    "\n",
    "Finally, we will be logging into the [wandb](https://www.wandb.com/) serice using the login command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "WD_vnyLXZQzD",
    "outputId": "b2ff57b8-a147-4893-80bd-e40d18042f98"
   },
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "!pip install wandb -q\n",
    "\n",
    "# Code for TPU packages install\n",
    "# !curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pzM1_ykHaFur",
    "outputId": "58fa0ba8-b486-4b26-aaea-c0331b343b70"
   },
   "outputs": [],
   "source": [
    "# Importing stock libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# WandB – Import the wandb library\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "KvPxXdKJguYB",
    "outputId": "6c523635-a25a-429b-cbd8-7b8bf9636972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "# Checking out the GPU we have access to. This is output is from the google colab version. \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLxxwd1scQNv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = torch.device(4) if cuda.is_available() else torch.device('cpu')\n",
    "device\n",
    "# Preparing for TPU usage\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "# device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "L-ePh9dEKXMw",
    "outputId": "a35fd305-1c09-48ff-978c-fa1d0762c5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/fanli/.netrc\n"
     ]
    }
   ],
   "source": [
    "# Login to wandb to log the model run and all the parameters\n",
    "!wandb login #0bb1fe48885469a7c6ad87a0d4e7dbbf5ef052b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section02'></a>\n",
    "### Preparing the Dataset for data processing: Class\n",
    "\n",
    "We will start with creation of Dataset class - This defines how the text is pre-processed before sending it to the neural network. This dataset will be used the the Dataloader method that will feed  the data in batches to the neural network for suitable training and processing. \n",
    "The Dataloader and Dataset will be used inside the `main()`.\n",
    "Dataset and Dataloader are constructs of the PyTorch library for defining and controlling the data pre-processing and its passage to neural network. For further reading into Dataset and Dataloader read the [docs at PyTorch](https://pytorch.org/docs/stable/data.html)\n",
    "\n",
    "#### *CustomDataset* Dataset Class\n",
    "- This class is defined to accept the Dataframe as input and generate tokenized output that is used by the **T5** model for training. \n",
    "- We are using the **T5** tokenizer to tokenize the data in the `text` and `ctext` column of the dataframe. \n",
    "- The tokenizer uses the ` batch_encode_plus` method to perform tokenization and generate the necessary outputs, namely: `source_id`, `source_mask` from the actual lyric text and `target_id` and `target_mask` from the title text.\n",
    "- To read further into the tokenizer, [refer to this document](https://huggingface.co/transformers/model_doc/t5.html#t5tokenizer)\n",
    "- The *CustomDataset* class is used to create 2 datasets, for training and for validation.\n",
    "- *Training Dataset* is used to fine tune the model: **80% of the original data**\n",
    "- *Validation Dataset* is used to evaluate the performance of the model. The model has not seen this data during training. \n",
    "\n",
    "#### Dataloader: Called inside the `main()`\n",
    "- Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of data loaded to the memory and then passed to the neural network needs to be controlled.\n",
    "- This control is achieved using the parameters such as `batch_size` and `max_len`.\n",
    "- Training and Validation dataloaders are used in the training and validation part of the flow respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "932p8NhxeNw4"
   },
   "outputs": [],
   "source": [
    "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.title\n",
    "        self.ctext = self.data.ctext\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section03'></a>\n",
    "### Fine Tuning the Model: Function\n",
    "\n",
    "Here we define a training function that trains the model on the training dataset created above, specified number of times (EPOCH), An epoch defines how many times the complete data will be passed through the network. \n",
    "\n",
    "This function is called in the `main()`\n",
    "\n",
    "Following events happen in this function to fine tune the neural network:\n",
    "- The epoch, tokenizer, model, device details, testing_ dataloader and optimizer are passed to the `train ()` when its called from the `main()`\n",
    "- The dataloader passes data to the model based on the batch size.\n",
    "- `language_model_labels` are calculated from the `target_ids` also, `source_id` and `attention_mask` are extracted.\n",
    "- The model outputs first element gives the loss for the forward pass. \n",
    "- Loss value is used to optimize the weights of the neurons in the network.\n",
    "- After every 10 steps the loss value is logged in the wandb service. This log is then used to generate graphs for analysis. Such as [these](https://wandb.ai/victorlifan/transformers_tutorials_summarization?workspace=user-victorlifan)\n",
    "- After every 500 steps the loss value is printed in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SaPAR7TWmxoM"
   },
   "outputs": [],
   "source": [
    "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
    "# The model is put into train mode and then we enumerate over the training loader and passed to the defined network \n",
    "\n",
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        if _%10 == 0:\n",
    "            wandb.log({\"Training Loss\": loss.item()})\n",
    "\n",
    "        if _%500==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # xm.optimizer_step(optimizer)\n",
    "        # xm.mark_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section04'></a>\n",
    "### Validating the Model Performance: Function\n",
    "\n",
    "During the validation stage we pass the unseen data(Testing Dataset), trained model, tokenizer and device details to the function to perform the validation run. This step generates new summary for dataset that it has not seen during the training session. \n",
    "\n",
    "This function is called in the `main()`\n",
    "\n",
    "This unseen data is the 20% of `lyrics-data.csv` which was seperated during the Dataset creation stage. \n",
    "During the validation stage the weights of the model are not updated. We use the generate method for generating new text for the summary. \n",
    "\n",
    "It depends on the `Beam-Search coding` method developed for sequence generation for models with LM head. \n",
    "\n",
    "The generated titles and originally titles are decoded from tokens to text and returned to the `main()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[text_generation parameters](https://huggingface.co/docs/transformers/v4.19.2/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9TNdHlQ0CLz"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length=24, \n",
    "                min_length = 1,\n",
    "                num_beams=5,\n",
    "                early_stopping=True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            if _%100==0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section05'></a>\n",
    "### Main Function\n",
    "\n",
    "The `main()` as the name suggests is the central location to execute all the functions/flows created above in the notebook. The following steps are executed in the `main()`:\n",
    "\n",
    "\n",
    "<a id='section501'></a>\n",
    "#### Initializing WandB \n",
    "\n",
    "* The `main()` begins with initializing WandB run under a specific project. This command initiates a new run for each execution of this command. \n",
    "\n",
    "* Before we proceed any further i will give a brief overview of the **[WandB Service](https://www.wandb.com/)**\n",
    "\n",
    "* This service has been created to track ML experiments, Optimize the experiments and save artifacts. It is designed to seamlessly integrate with all the Machine Learning and Deep Learning Frameworks. Each script can be organized into *Project* and each execution of the script will be registered as a *run* in the respective project.\n",
    "\n",
    "* The service can be configured to log several default metrics, such a network weights, hardware usage, gradients and weights of the network. \n",
    "\n",
    "* It can also be used to log user defined metrics, such a loss in the `train()`.\n",
    "\n",
    "* This particular tutorial is logged in the project: **[transformers_tutorials_summarization](https://wandb.ai/victorlifan/transformers_tutorials_summarization)**\n",
    "\n",
    "**One of the charts from the project**\n",
    "![](meta/wandb.png)\n",
    "\n",
    "* Visit the project page to see the details of different runs and what information is logged by the service. \n",
    "\n",
    "* Following the initialization of the WandB service we define configuration parameters that will be used across the tutorial such as `batch_size`, `epoch`, `learning_rate` etc.\n",
    "\n",
    "* These parameters are also passed to the WandB config. The config construct with all the parameters can be optimized using the Sweep service from WandB. Currently, that is outof scope of this tutorial. \n",
    "\n",
    "* Next we defining seed values so that the experiment and results can be reproduced.\n",
    "\n",
    "\n",
    "<a id='section502'></a>\n",
    "#### Importing and Pre-Processing the domain data\n",
    "\n",
    "We will be working with the data and preparing it for fine tuning purposes. \n",
    "*Assuming that the `lyrics-data.csv` is already downloaded in your `data` folder*\n",
    "\n",
    "* The file is imported as a dataframe and give it the headers as per the documentation.\n",
    "* Cleaning the file to remove the unwanted columns.\n",
    "* A new string is added to the main article column `summarize: ` prior to the actual article. This is done because **T5** had similar formatting for the summarization dataset. \n",
    "* The final Dataframe will be something like this:\n",
    "\n",
    "|title|ctext|\n",
    "|--|--|\n",
    "|title-1|summarize: lyric 1|\n",
    "|title-2|summarize: lyric 2|\n",
    "|title-3|summarize: lyric 3|\n",
    "\n",
    "* Top 5 rows of the dataframe are printed on the console.\n",
    "\n",
    "<a id='section503'></a>\n",
    "#### Creation of Dataset and Dataloader\n",
    "\n",
    "* The updated dataframe is divided into 80-20 ratio for test and validation. \n",
    "* Both the data-frames are passed to the `CustomerDataset` class for tokenization of the new articles and their summaries.\n",
    "* The tokenization is done using the length parameters passed to the class.\n",
    "* Train and Validation parameters are defined and passed to the `pytorch Dataloader contstruct` to create `train` and `validation` data loaders.\n",
    "* These dataloaders will be passed to `train()` and `validate()` respectively for training and validation action.\n",
    "* The shape of datasets is printed in the console.\n",
    "\n",
    "\n",
    "<a id='section504'></a>\n",
    "#### Neural Network and Optimizer\n",
    "\n",
    "* In this stage we define the model and optimizer that will be used for training and to update the weights of the network. \n",
    "* We are using the `t5-base` transformer model for our project. You can read about the `T5 model` and its features above. \n",
    "* We use the `T5ForConditionalGeneration.from_pretrained(\"t5-base\")` commad to define our model. The `T5ForConditionalGeneration` adds a Language Model head to our `T5 model`. The Language Model head allows us to generate text based on the training of `T5 model`.\n",
    "* We are using the `Adam` optimizer for our project. This has been a standard for all our tutorials and is something that can be changed updated to see how different optimizer perform with different learning rates. \n",
    "* There is also a scope for doing more with Optimizer such a decay, momentum to dynamically update the Learning rate and other parameters. All those concepts have been kept out of scope for these tutorials. \n",
    "\n",
    "\n",
    "<a id='section505'></a>\n",
    "#### Training Model and Logging to WandB\n",
    "\n",
    "* Now we log all the metrics in WandB project that we have initialized above.\n",
    "* Followed by that we call the `train()` with all the necessary parameters.\n",
    "* Loss at every 500th step is printed on the console.\n",
    "* Loss at every 10th step is logged as Loss in the WandB service.\n",
    "\n",
    "\n",
    "<a id='section506'></a>\n",
    "#### Validation and generation of Summary\n",
    "\n",
    "* After the training is completed, the validation step is initiated.\n",
    "* As defined in the validation function, the model weights are not updated. We use the fine tuned model to generate new titles based on the song lyric.\n",
    "* An output is printed on the console giving a count of how many steps are complete after every 100th step. \n",
    "* The original title and generated title are converted into a list and returned to the main function. \n",
    "* Both the lists are used to create the final dataframe with 2 columns **Generated Title** and **Actual Title**\n",
    "* The dataframe is saved as a csv file in the local drive.\n",
    "* A qualitative analysis can be done with the Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 691,
     "referenced_widgets": [
      "694ec243104f470093820e5e0dbbfc8e",
      "730be2945e39401dac1ac1247cf2d5fb",
      "71a4e2121f554668b2fd6461de3b2dcb",
      "9218011c0e1544ffb8128e0add0439c6",
      "9754d7526eb249d6ba849cb30f415ffc",
      "6afe5bad5a2b4e8c94791949b0f08ead",
      "4fca290286b3402fae9ddd0b1ce54504",
      "ae78c7bf57934f03a0f553b8829e44d4",
      "5c5331a892a64b95a2a130d7cb953e27",
      "a84d01823be4413db834ac23cffd9c26",
      "7b6f595e9c6a45f9b1edc6bd5512d205",
      "662b4ba823df409d8169696c81dccb46",
      "94d2a8fa47a3440a8332cb36036ea68e",
      "98459f90e8e94b29b93f576b5fdebe58",
      "e46fe62d895043878985a1014c3d853a",
      "a7edcb37126443c298eca2251194bb66",
      "54502d44bc774e2cb8067b59faa3f1bf",
      "1e6cc5a0d54c4fdab326fcaa2660e781",
      "ec8ba72354fd4b1d92c3b7d061e3c464",
      "d9627b05dcda4043aa149c940d7d2f57",
      "caf8968694c64b4fbbf5a15ed4948c34",
      "bb96976987544a5f800e71f2124b97dd",
      "4ee0316176b245239434bd88fe8f8572",
      "a0002b369f23475ca440c59df649e450"
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZtNs9ytpCow2",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "80545587-0a82-455a-a9ba-13eb3fcb1550",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvictorlifan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/fanli/Desktop/classes/summer_631/project/song_title_generation/notebooks/wandb/run-20220607_183613-37ndwkja</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/victorlifan/transformers_tutorials_summarization/runs/37ndwkja\" target=\"_blank\">magic-frost-40</a></strong> to <a href=\"https://wandb.ai/victorlifan/transformers_tutorials_summarization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                title                                              ctext\n",
      "0    careless whisper  summarize: i feel so unsure as i take your han...\n",
      "1  could you be loved  summarize: don't let them fool, ya or even try...\n",
      "2            cruisin'  summarize: baby, let's cruise, away from here ...\n",
      "3                easy  summarize: know it sounds funny but, i just ca...\n",
      "4     for your babies  summarize: you've got that look again the one ...\n",
      "FULL Dataset: (191814, 2)\n",
      "TRAIN Dataset: (153451, 2)\n",
      "TEST Dataset: (38363, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Fine-Tuning for the model on our dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanli/opt/anaconda3/envs/bc/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  6.86549711227417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4fec62ab01ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-4fec62ab01ce>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7b1779cfacca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, tokenizer, model, device, loader, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1596\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1599\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1028\u001b[0m                 )\n\u001b[1;32m   1029\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1031\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    570\u001b[0m     ):\n\u001b[1;32m    571\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         )  # (batch_size, n_heads, seq_length, key_length)\n\u001b[0;32m--> 535\u001b[0;31m         attn_weights = nn.functional.dropout(\n\u001b[0m\u001b[1;32m    536\u001b[0m             \u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         )  # (batch_size, n_heads, seq_length, key_length)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bc/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # WandB – Initialize a new run\n",
    "    wandb.init(project=\"transformers_tutorials_summarization\")\n",
    "\n",
    "    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
    "    # Defining some key variables that will be used later on in the training  \n",
    "    config = wandb.config          # Initialize config\n",
    "    config.TRAIN_BATCH_SIZE = 16   # input batch size for training (default: 64)\n",
    "    config.VALID_BATCH_SIZE = 16    # input batch size for testing (default: 1000)\n",
    "    config.TRAIN_EPOCHS = 10        # number of epochs to train (default: 10)\n",
    "    config.VAL_EPOCHS = 1 \n",
    "    config.LEARNING_RATE = 1e-5    # learning rate (default: 0.01)\n",
    "    config.SEED = 42               # random seed (default: 42)\n",
    "    config.MAX_LEN = 512\n",
    "    config.SUMMARY_LEN = 24 \n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(config.SEED) # pytorch random seed\n",
    "    np.random.seed(config.SEED) # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "    \n",
    "\n",
    "    # Importing and Pre-Processing the domain data\n",
    "    # Selecting the needed columns only. \n",
    "    # Adding the 'summarzie' text in front of the lyric. This is to format the dataset similar to how T5 model was trained for summarization task. \n",
    "    df = pd.read_csv('../data/renamed_clean.csv',encoding='latin-1')\n",
    "    df = df[['title','ctext']]\n",
    "    df.ctext = 'summarize: ' + df.ctext\n",
    "    print(df.head())\n",
    "\n",
    "    \n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
    "    train_size = 0.8\n",
    "    train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
    "    val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    print(\"FULL Dataset: {}\".format(df.shape))\n",
    "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "    print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
    "\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    val_params = {\n",
    "        'batch_size': config.VALID_BATCH_SIZE,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "\n",
    "    \n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "    # Log metrics with wandb\n",
    "    wandb.watch(model, log=\"all\")\n",
    "    # Training loop\n",
    "    print('Initiating Fine-Tuning for the model on our dataset')\n",
    "\n",
    "    for epoch in range(config.TRAIN_EPOCHS):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "\n",
    "\n",
    "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
    "    # Saving the dataframe as predictions.csv\n",
    "    print('Now generating titles on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
    "    for epoch in range(config.VAL_EPOCHS):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({'Generated Title':predictions,'Actual Title':actuals})\n",
    "        final_df.to_csv('notebook_predictions.csv')\n",
    "        print('Output Files generated for review')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='section06'></a>\n",
    "### Examples of the Titles Generated from the model\n",
    "### Three versions of model performance comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('../results/predictions.csv',index_col=0)\n",
    "result_df2 = pd.read_csv('../results/V2_predictions.csv',index_col=0)\n",
    "result_df3 = pd.read_csv('../results/V3_predictions.csv',index_col=0)\n",
    "# randomly select 20 songs from validation set\n",
    "idx = np.random.randint(0,high = len(result_df),size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.iloc[idx].rename({\"Generated Title\":\"V1_Generated Title\"},axis = 1)\n",
    "result_df2 = result_df2.iloc[idx].rename({\"Generated Title\":\"V2_Generated Title\"},axis = 1)['V2_Generated Title']\n",
    "result_df3 = result_df3.iloc[idx].rename({\"Generated Title\":\"V3_Generated Title\"},axis = 1)['V3_Generated Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = result_df.join(result_df2).join(result_df3).iloc[:,[0,2,3,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with `autotrain-song_title_generate-939531516`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers.utils import logging\n",
    "# supress warning\n",
    "logging.set_verbosity(40)\n",
    "\n",
    "\n",
    "def generate(lyric):\n",
    "        \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"victorlifan/autotrain-song_title_generate-939531516\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"victorlifan/autotrain-song_title_generate-939531516\")\n",
    "    \n",
    "    inputs = tokenizer.encode(\"summarize: \" + lyric, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=24, min_length=1, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    result = tokenizer.decode(outputs[0])\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# inference on valid set\n",
    "Autotrain_Generated_Title = []\n",
    "\n",
    "for i in result_df['Actual Title'][idx]:\n",
    "    \n",
    "    lyric = df[df['title']==i]['ctext'].values[0]\n",
    "    title = generate(lyric)\n",
    "    Autotrain_Generated_Title.append(title.strip('<pad> ').strip('</s>'))\n",
    "    # #print(f\"song id: {idx}\\n\")\n",
    "    # print(f\"actual title: {i}\\n\")\n",
    "    # print(f\"generated title: {title}\\n\")\n",
    "    # #print(f\"lyrics: {df['Lyric'][idx]}\\n\")\n",
    "    # print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_Generated Title</th>\n",
       "      <th>V2_Generated Title</th>\n",
       "      <th>V3_Generated Title</th>\n",
       "      <th>Autotrain_Generated_Title</th>\n",
       "      <th>Actual Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>believer</td>\n",
       "      <td>believer</td>\n",
       "      <td>believer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15841</th>\n",
       "      <td>cyco</td>\n",
       "      <td>cyco</td>\n",
       "      <td>cyco</td>\n",
       "      <td>born to be cyco</td>\n",
       "      <td>cyco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36533</th>\n",
       "      <td>thresh</td>\n",
       "      <td>thresh</td>\n",
       "      <td>andro queen</td>\n",
       "      <td>ndro queen</td>\n",
       "      <td>andro queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17755</th>\n",
       "      <td>affixed</td>\n",
       "      <td>affixed</td>\n",
       "      <td>affixed by disconcern</td>\n",
       "      <td>ffixed by discontent</td>\n",
       "      <td>affixed by disconcern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>NaN</td>\n",
       "      <td>- make it up</td>\n",
       "      <td>as you go</td>\n",
       "      <td>make it up as you go</td>\n",
       "      <td>make it up as you go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25176</th>\n",
       "      <td>a beauty thing</td>\n",
       "      <td>a beauty thing</td>\n",
       "      <td>promise</td>\n",
       "      <td>miracle belief</td>\n",
       "      <td>promised you a miracle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11066</th>\n",
       "      <td>the boys</td>\n",
       "      <td>'cile</td>\n",
       "      <td>me love boys</td>\n",
       "      <td>me love boy</td>\n",
       "      <td>brazilian boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>- again and again</td>\n",
       "      <td>again and again</td>\n",
       "      <td>gain and again</td>\n",
       "      <td>again and again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25188</th>\n",
       "      <td>- killing andy warhol</td>\n",
       "      <td>the killing andy warhol</td>\n",
       "      <td>killing andy warhol</td>\n",
       "      <td>killing andy warhol</td>\n",
       "      <td>killing andy warhol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16637</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hate the hate</td>\n",
       "      <td>the human strain</td>\n",
       "      <td>human strain</td>\n",
       "      <td>human strain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1_Generated Title       V2_Generated Title     V3_Generated Title  \\\n",
       "18206                    NaN                      NaN               believer   \n",
       "15841                   cyco                     cyco                   cyco   \n",
       "36533                 thresh                   thresh            andro queen   \n",
       "17755                affixed                  affixed  affixed by disconcern   \n",
       "28636                    NaN             - make it up              as you go   \n",
       "...                      ...                      ...                    ...   \n",
       "25176         a beauty thing           a beauty thing                promise   \n",
       "11066               the boys                    'cile           me love boys   \n",
       "5356                     NaN        - again and again        again and again   \n",
       "25188  - killing andy warhol  the killing andy warhol    killing andy warhol   \n",
       "16637                    NaN            hate the hate       the human strain   \n",
       "\n",
       "      Autotrain_Generated_Title            Actual Title  \n",
       "18206                  believer                believer  \n",
       "15841           born to be cyco                    cyco  \n",
       "36533                ndro queen             andro queen  \n",
       "17755      ffixed by discontent   affixed by disconcern  \n",
       "28636      make it up as you go    make it up as you go  \n",
       "...                         ...                     ...  \n",
       "25176            miracle belief  promised you a miracle  \n",
       "11066               me love boy          brazilian boys  \n",
       "5356             gain and again         again and again  \n",
       "25188       killing andy warhol     killing andy warhol  \n",
       "16637              human strain            human strain  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df['Autotrain_Generated_Title'] = Autotrain_Generated_Title\n",
    "comb_df = comb_df.iloc[:,[0,1,2,4,3]]\n",
    "comb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.to_csv('../results/comb_prediction_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "[PyTorch Transformers Tutorials](https://github.com/abhimishra91/transformers-tutorials)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transformers_summarization_wandb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e6cc5a0d54c4fdab326fcaa2660e781": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ee0316176b245239434bd88fe8f8572": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fca290286b3402fae9ddd0b1ce54504": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54502d44bc774e2cb8067b59faa3f1bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec8ba72354fd4b1d92c3b7d061e3c464",
       "IPY_MODEL_d9627b05dcda4043aa149c940d7d2f57"
      ],
      "layout": "IPY_MODEL_1e6cc5a0d54c4fdab326fcaa2660e781"
     }
    },
    "5c5331a892a64b95a2a130d7cb953e27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b6f595e9c6a45f9b1edc6bd5512d205",
       "IPY_MODEL_662b4ba823df409d8169696c81dccb46"
      ],
      "layout": "IPY_MODEL_a84d01823be4413db834ac23cffd9c26"
     }
    },
    "662b4ba823df409d8169696c81dccb46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7edcb37126443c298eca2251194bb66",
      "placeholder": "​",
      "style": "IPY_MODEL_e46fe62d895043878985a1014c3d853a",
      "value": " 1.20k/1.20k [00:16&lt;00:00, 73.7B/s]"
     }
    },
    "694ec243104f470093820e5e0dbbfc8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_71a4e2121f554668b2fd6461de3b2dcb",
       "IPY_MODEL_9218011c0e1544ffb8128e0add0439c6"
      ],
      "layout": "IPY_MODEL_730be2945e39401dac1ac1247cf2d5fb"
     }
    },
    "6afe5bad5a2b4e8c94791949b0f08ead": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71a4e2121f554668b2fd6461de3b2dcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6afe5bad5a2b4e8c94791949b0f08ead",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9754d7526eb249d6ba849cb30f415ffc",
      "value": 791656
     }
    },
    "730be2945e39401dac1ac1247cf2d5fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b6f595e9c6a45f9b1edc6bd5512d205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98459f90e8e94b29b93f576b5fdebe58",
      "max": 1199,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_94d2a8fa47a3440a8332cb36036ea68e",
      "value": 1199
     }
    },
    "9218011c0e1544ffb8128e0add0439c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae78c7bf57934f03a0f553b8829e44d4",
      "placeholder": "​",
      "style": "IPY_MODEL_4fca290286b3402fae9ddd0b1ce54504",
      "value": " 792k/792k [00:00&lt;00:00, 2.85MB/s]"
     }
    },
    "94d2a8fa47a3440a8332cb36036ea68e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9754d7526eb249d6ba849cb30f415ffc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "98459f90e8e94b29b93f576b5fdebe58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0002b369f23475ca440c59df649e450": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7edcb37126443c298eca2251194bb66": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a84d01823be4413db834ac23cffd9c26": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae78c7bf57934f03a0f553b8829e44d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb96976987544a5f800e71f2124b97dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caf8968694c64b4fbbf5a15ed4948c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d9627b05dcda4043aa149c940d7d2f57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0002b369f23475ca440c59df649e450",
      "placeholder": "​",
      "style": "IPY_MODEL_4ee0316176b245239434bd88fe8f8572",
      "value": " 892M/892M [00:15&lt;00:00, 57.8MB/s]"
     }
    },
    "e46fe62d895043878985a1014c3d853a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec8ba72354fd4b1d92c3b7d061e3c464": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb96976987544a5f800e71f2124b97dd",
      "max": 891691430,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_caf8968694c64b4fbbf5a15ed4948c34",
      "value": 891691430
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
